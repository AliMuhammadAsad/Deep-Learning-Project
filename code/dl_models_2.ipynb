{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Implementation\n",
    "\n",
    "1. Data Loading\n",
    "2. Label + One-Hot Encoding\n",
    "3. Tokenization + Padding\n",
    "4. Embedding\n",
    "5. Data Splitting\n",
    "6. Model Implementation\n",
    "\n",
    "| Model | Accuracy |\n",
    "| --- | --- |\n",
    "| LSTM | |\n",
    "| Bi-LSTM | |\n",
    "| GRU | |\n",
    "| Bi-GRU | |\n",
    "| 1D-CNN | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 01:30:28.431418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731184228.470932   54325 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731184228.479172   54325 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 01:30:28.508137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, joblib\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Bidirectional, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab import drive\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Embedding, LSTM, GRU, Bidirectional, Dense\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abbasinYousuf': 0, 'hamzaBaba': 1, 'karanKhan': 2, 'khatirAfridi': 3, 'khushalKhanKhattak': 4, 'matiullahTurab': 5, 'mumtazOrakazi': 6, 'munirJan': 7, 'naeemAhmed': 8, 'rabiaMumtaz': 9, 'rahmanBaba': 10, 'rehmatShah': 11, 'sahibShahSabir': 12}\n"
     ]
    }
   ],
   "source": [
    "# Define Data directory\n",
    "DATA_DIR = '../data/'\n",
    "\n",
    "# list of poet names\n",
    "# Removed the 5 lowest poets\n",
    "poets = [\"abbasinYousuf\", \"hamzaBaba\", \"karanKhan\", \"khatirAfridi\", \"khushalKhanKhattak\", \"matiullahTurab\", \"mumtazOrakazi\", \"munirJan\", \"naeemAhmed\", \"rabiaMumtaz\", \"rahmanBaba\", \"rehmatShah\", \"sahibShahSabir\"]\n",
    "\n",
    "# # Pehle k 13\n",
    "# poets = [\"abbasinYousuf\", \"azizMazerwal\", \"ghaniKhan\", \"hamzaBaba\", \"khaliqZiari\", \"khatirAfridi\", \"khushalKhanKhattak\",  \"mumtazOrakazi\", \"munirJan\",  \"rahmanBaba\", \"rehmatShah\", \"sahibShahSabir\", \"salimRiaz\"]\n",
    "\n",
    "## All\n",
    "# poets = [\"abbasinYousuf\", \"azizMazerwal\", \"ghaniKhan\", \"hamzaBaba\", \"karanKhan\", \"khaliqZiari\", \"khatirAfridi\", \"khushalKhanKhattak\", \"matiullahTurab\", \"mumtazOrakazi\", \"munirJan\", \"naeemAhmed\", \"rabiaMumtaz\", \"rahmanBaba\", \"rehmatShah\", \"sahibShahSabir\", \"salimRiaz\"]\n",
    "\n",
    "poet_labels = {poet: i for i, poet in enumerate(poets)}\n",
    "print(poet_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Label the Data\n",
    "def load_and_label(data_dir, poets, poet_labels):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for poet in poets:\n",
    "        poet_dir = os.path.join(data_dir, poet)\n",
    "        file_path = os.path.join(poet_dir, f'{poet}.txt')\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f'{file_path} does not exist')\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            data.extend(lines)\n",
    "            labels.extend([poet_labels[poet]] * len(lines))\n",
    "\n",
    "    df = pd.DataFrame({'text': data, 'label': labels})\n",
    "    return data, labels, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36629.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.326217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.542465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  36629.000000\n",
       "mean       5.326217\n",
       "std        3.542465\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        8.000000\n",
       "max       12.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels, df = load_and_label(DATA_DIR, poets, poet_labels)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PoemClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten along the sequence length dimension\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poems_train, poems_temp, labels_train, labels_temp = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
    "poems_val, poems_test, labels_val, labels_test = train_test_split(poems_temp, labels_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "poems_train_tfidf = tfidf_vectorizer.fit_transform(poems_train).toarray()\n",
    "poems_val_tfidf = tfidf_vectorizer.transform(poems_val).toarray()\n",
    "poems_test_tfidf = tfidf_vectorizer.transform(poems_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_train_tfidf = poems_train_tfidf.reshape(poems_train_tfidf.shape[0], 1, poems_train_tfidf.shape[1])\n",
    "poems_val_tfidf = poems_val_tfidf.reshape(poems_val_tfidf.shape[0], 1, poems_val_tfidf.shape[1])\n",
    "poems_test_tfidf = poems_test_tfidf.reshape(poems_test_tfidf.shape[0], 1, poems_test_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PoemClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history, title=\"Model Training\"):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731184238.356660   54325 gpu_device.cc:2433] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "W0000 00:00:1731184238.358461   54325 gpu_device.cc:2433] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 5.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1731184238.452124   54325 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3503 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:02:00.0, compute capability: 5.0\n",
      "2024-11-10 01:30:39.481488: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 586060000 exceeds 10% of free system memory.\n",
      "2024-11-10 01:30:40.239583: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 586060000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "F0000 00:00:1731184242.605135   54325 concat_lib_gpu_impl.cu.cc:151] Non-OK-status: GpuLaunchKernel( concat_fixed_kernel<T, IntType>, config.block_count, config.thread_per_block, 0, gpu_device.stream(), input_ptrs, split_size, static_cast<int>(output->dimension(0)), static_cast<int>(output->dimension(1)), output->data())\n",
      "Status: INTERNAL: no kernel image is available for execution on the device\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Define the LSTM Model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, input_shape=(X_train_tfidf.shape[1], X_train_tfidf.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(64, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(len(set(encoded_labels)), activation='softmax'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Define the early stopping callback\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_tfidf, y_train, validation_data=(X_vals_tfidf, y_vals), epochs=10, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(30)))\n",
    "model.add(Dense(len(set(encoded_labels)), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(poems_train_tfidf, labels_train, validation_data=(poems_val_tfidf, labels_val), epochs=10, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_history(history, title=\"Second LSTM Model (TF-IDF) Training\")\n",
    "\n",
    "# # Evaluate on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_probs = model.predict(X_test_tfidf)\n",
    "# y_preds = np.argmax(y_probs, axis=1)\n",
    "\n",
    "# # Confusion Matrix\n",
    "# confusion_matrix = confusion_matrix(y_test, y_preds)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(confusion_matrix, annot=True, fmt='d', xticklabels=poets, yticklabels=poets)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix - LSTM Model (TF-IDF)')\n",
    "\n",
    "# # Classification Report\n",
    "# classification_rep = classification_report(y_test, y_preds, target_names=poets)\n",
    "# print(classification_rep)\n",
    "# plt.show()\n",
    "\n",
    "plot_training_history(history, title=\"Second LSTM Model (TF-IDF) Training\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(poems_test_tfidf, labels_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_probs = model.predict(poems_test_tfidf)\n",
    "y_preds = np.argmax(y_probs, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = confusion_matrix(labels_test, y_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', xticklabels=poets, yticklabels=poets)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - LSTM Model (TF-IDF)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

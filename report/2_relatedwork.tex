\section{Related Work}

Poet attribution using deep learning and machine learning has been explored in various languages previously as well. 

% A study was conducted for poet attribution of Urdu Ghazals \cite{fizza_iqra_urdu_attribution} using machine learning, deep learning, and transformer based techniques on a dataset of 18609 couplets of 15 of the most notable Urdu ghazal poets, taking an analytical approach to capture the writing styles of Urdu Ghazal poets of an equal blend from the 19th-20th century, and the 18th-19th century era, which shows considerable differences in terms of word usage, style, and dialects which is ultimately beneficial for the model to identify patterns. This study experimented with four machine learning models; Logistic Regression, Random Forest, Naive Bayes, and SVMs. They first implemented label encodings to convert labels into numeric values to be fed into the machine learning model, followed by TF-IDF Feature Extraction using SKlearn library's TfidfVectorizer to obtain features best for training the model. They also used 4 deep learning models; Flatten, LSTM, GRU, and 1D-CNN, with label and one-hot encoding to convert categorical data into numerical values, followed by tokenization to generate sequences and a word-index dictionary, which was then passed to an embedding layer on a standard dimension of 300 neurons. Lastly, they used state-of-the-art (sota) NLP models, mainly roBerta-Urdu-model and Bert-base multilingual-uncased model. They received the best scores on Bert and roBerta with 80.32\% and 79.52\% accuracy respectively. SVM and Logistic Regression performed better than deep learning methods though with 64\% and 60\% accuracies respectively. LSTMs performed the best amongst the deep learning models with a 59.96\% accuracy. They highlight the class imbalance between classes which might have resulted in lower accuracies, but show the superiority of transformer models in poet attribution tasks that achieve better results than traditional machine learning models.

A study on poet attribution for Urdu Ghazals \cite{fizza_iqra_urdu_attribution} employed machine learning, deep learning, and transformer-based techniques on a dataset of 18,609 couplets from 15 notable Urdu poets, covering both the 18th-19th and 19th-20th centuries. The distinct word usage and styles across these periods benefited the model in identifying patterns. The study tested four machine learning models — Logistic Regression, Random Forest, Naive Bayes, and SVM — using label encodings and TF-IDF for feature extraction. They also experimented with four deep learning models: Flatten, LSTM, GRU, and 1D-CNN, utilizing one-hot encoding and tokenization with a 300-dimensional embedding layer. The best performance came from transformer models: Bert and roBerta achieved 80.32\% and 79.52\% accuracy, respectively, outperforming deep learning methods. Among traditional machine learning models, SVM and Logistic Regression achieved 64\% and 60\% accuracy, surpassing deep learning approaches, where LSTM performed best at 59.96\%. The study notes class imbalance as a challenge but emphasizes the superior performance of transformer models in poet attribution tasks.

Another study was conducted on the classification of Persian poetry based on the poet's era \cite{persian_poetry_classification}. The authors used the Persian Hafez's Ghazal dataset which contained 496 Persian Ghazals. The authors categorized Persian Ghazals based on the poetic era in which they were written, with the classification focusing on distinguishiing Hafez's ghazals by the time period or era associated with the poetry using sequential learning architectures. Word embeddings were used, an important technique in NLP, and deep learning classification models. In addition, they also used Bag Of Words (BOW) - a baseline statistical model for textual feature extraction, and Latent Dirichlet Allocation (LDA) for feature extraction. They also used Distributed Memory (DM) for vectorization, and concatenated Distributed BOW with DM. Then they trained Machine Learning (ML) and Deep Learning (DL) models including Random Forest, Logistic Regression, LSTMs, GRU, and Bi-LSTM. For evaluation, they used accuracy, F1 score, precision, and recall to evaluate the performance of their models. The ML models were compared to SVM, which performed better in terms of accuracy but not F1 score. In the DL models, LSTM gave highest accuracy of 77.8\% and the highest F1-score of 76.6\% on the Persian dataset.  

We also came across a study that classified Gujrati Poetry based on emotions using deep learning techniques \cite{gujrati_poetry_attribution}. The author collected the first Gujrati poetry dataset of more than 300 different Gujrati poems, and called it the ``Kavan'' dataset that represented the different ``Rasa's'' emotions. They further used the NLTK library in Python for tokenization and labelling of the data. Poems were used as input one by one, with each word compared to a metadata based on the ``Navarasa'' concept, returning values between 0 and 8 for the emotions. They implemented a Deep Learning classifier model, and achieved an 87.62\% accuracy. 

In addition to classification and attribution, another study aimed to perform a comparative analysis on various machine learning models for Urdu poet attribution \cite{urdu_poet_attribution_kiet}. They collected a total of 1563 poems from 5 famous Urdu poets. They also tokenized the data using Python's NLTK library, however, they did not remove stop words as they believed that such functions are important in modeling the style of the author. They repeated various experiments on various models repeatedly with different parameters, to conclude that SVM performed the best over most configurations with the highest accuracy of 88.7\% and an average accuracy of 81\%, with Naive Bayes at a close second with the highest accuracy of 84\% and an average accuracy of 77\%. They also implemented LSTM models, however, the highest accuracy they received was 45.78\%. They concluded that with over 100 samples per poet and more than 2 lines per sample, one could achieve good results in poet attribution. 

Regarding Urdu language we found another research on the poet attribution on urdu authorship of poets \cite{urdu_authorship_attribution}. They collected a total of 11406 couplets from nonsocial Urdu websites of mainly 3 different Urdu poets. They developed various models for classification including SVM, Multilayer Perceptron (MLP), Multinomial Naive Bayes, and Multinomial MLP Pre-Trained Word2Vec model. SVMs achieved the highest accuracy and F1-score of 82.85\% and 82.67\%. 

Another similar work was done on identification of Urdu Ghazals using SVM \cite{urdu_ghazal_svm}. The authors collected a total of 3967 couplets from 4 poets, and generated a total of one million tokens from the dataset with a vocabulary size of 6427. They also created a Term-Document Frequency (TDF) matrix with rows representing couplets and columns representing unique terms. For feature selection, they used Chi-Square and L1-based techniques to select the best features. The Chi-Square evaluates feature importance based on statistical independence, while L1-based selection focuses on non-zero regression coefficients. They selected a total of 5 models; Naive Bayes, Decision Trees, SVMs, KNNs, and Random Forest. Overall, SVMs performed the best out of all the models with an accuracy of 72\%, closely followed by Naive Bayes with an accuracy of 70\%.

We also found a study that used ML approaches for authorship attribution in Arabic poetry \cite{arabic_poetry_attribution}. They established various characteristic of Arabic poetry such as \textit{Meter (Wazn)} and \textit{Rhyme (qafiya)}, and curated a corpus of Arabic poetry of 73 poets with 18646 Qasidah's for training that amount upto 1856436 words. They used SVMs and Naive Bayes for classification, using Chi-Square and Information Gain for feature selection. They came up with 6 features corresponding to character, word length, sentences length, first word length, meter, and rhyme. They achieved the highest accuracy of 98.86\% on SVMs when all features were used, while on average SVM had an accuracy of 87.4\%. They also implemented a Naive Bayes model which had the highest accuracy of 98.86\% as well with only two features, and an average accuracy of 90.68\%. 

Apart from the aforementioned literature, various other works were also consulted that were relevant to our research. One study we came across was the first to work on Pashto text classification using language processing techniques for single and multi-label analysis \cite{pashto_text_classification}. They constructed a dataset of Pashto documents including Sports, History, Health, Scientific, Cultural, Economic, Political, and Technology based - although poetry wasn't included. They used DistilBERT-base-multilingual-cased model, Multilayer Perceptron, SVMs, KNNs, Decision Trees, Gaussian Naive Bayes, Multinomial Naive Bayes, Random Forest, and Logistic Regression models. They got a 94\% accuracy using MLP classification and TFIDF feature extraction. DistilBERT - a multilingual model which was not pretrained on Pashto still was able to achieve 66.31\% accuracy, thus, the authors conclude that this still gave promising results, and that the model could be further improved by developing a tokenizer specifically tailored for Pashto.   